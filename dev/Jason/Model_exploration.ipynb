{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Turns off annoying warnings. If there are ever serious data\n",
    "# errors, trying removing this line.\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_Kaggle_file(predict_probabilities, columns, output_file_name=\"auto\", decimal_limit=3):\n",
    "    \"\"\"\n",
    "    Outputs a file that can be submitted to Kaggle. This takes a long time to run, so you \n",
    "    shouldn't run it that often. Instead, just have good internal validation techniques so you\n",
    "    don't have to check the public leaderboard.\n",
    "    \n",
    "    Required imports: \n",
    "    import time\n",
    "    import pandas as pd\n",
    "    \n",
    "    predict_probabilities: array-like of shape = [n_samples, n_classes]. Is the output of a \n",
    "        predict_proba method of a sklearn classifier\n",
    "        \n",
    "    columns: array or list of column names that are in the same order as the columns of the \n",
    "        predict_probabilities method. If LabelEncoder was used, is accessed via the classes_ \n",
    "        attribute. Don't include an \"Id\" column.\n",
    "        \n",
    "    output_file_name: If \"auto\" names it sf_crime_test_predictions_<YearMonthDay-HourMinuteSecond>, \n",
    "        else uses the string entered as the file name.\n",
    "        \n",
    "    decimal_limit: If None uses full precision, else formats predictions based on that precision. \n",
    "        Can significantly reduce the filesize and make writing the file faster.\n",
    "        i.e. actual prediction = .2352452435, decimal_limit=2 --> .24, decimal_limit=3 --> .235, etc.\n",
    "    \"\"\"\n",
    "    predictions = pd.DataFrame(predict_probabilities, columns=columns)\n",
    "    predictions.index.name = \"Id\"\n",
    "    if output_file_name == \"auto\":\n",
    "        timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        output_file_name = \"sf_crime_test_predictions_\" + timestr + \".csv\"\n",
    "    if decimal_limit:\n",
    "        decimal_limit = '%%.%df' % decimal_limit\n",
    "    predictions.to_csv(output_file_name, float_format=decimal_limit)\n",
    "    print(\"Finished writing file: \", output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class FeatureEngineering(TransformerMixin):\n",
    "    def __init__(self, date_features=True, DayOfWeek_features=True, PdDistrict_features=True, Address_features=True):\n",
    "        self.date_features = date_features\n",
    "        self.DayOfWeek_features = DayOfWeek_features\n",
    "        self.PdDistrict_features = PdDistrict_features\n",
    "        self.Address_features = Address_features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Features from dates\n",
    "        if self.date_features:\n",
    "            X['Year'] = X.Dates.apply(lambda x: int(x[:4])) # Hypothesis: The distribution of crimes changed over time\n",
    "            X['Month'] = X.Dates.apply(lambda x: int(x[5:7])) # H: Certain crimes occur during some months more than others\n",
    "            X['Hour'] = X.Dates.apply(lambda x: int(x[11:13])) # H: Certain crimes occur at day, others at night\n",
    "            X['Minute'] = X.Dates.apply(lambda x: int(x[14:16])) # H: Certain crimes are rounded to the nearest hour\n",
    "            # Idea: Is holiday feature. H: Holidays --> Tourists --> Different types of crimes\n",
    "\n",
    "        # Features from DayOfWeek\n",
    "        if self.DayOfWeek_features:\n",
    "            X['DayOfWeekNum'] = X[\"DayOfWeek\"].map({\"Tuesday\":0, \"Wednesday\":1, \n",
    "                                                 \"Thursday\":2, \"Friday\":3, \n",
    "                                                 \"Saturday\":4, \"Sunday\":5, \n",
    "                                                 \"Monday\":6}) # H: Different days have different crime distributions\n",
    "            X['IsWeekend'] = X[\"DayOfWeekNum\"].apply(lambda x: 1*((x == 4) | (x == 5))) # H: Weekends are special\n",
    "\n",
    "        # Features from PdDistrict\n",
    "        if self.PdDistrict_features:\n",
    "            X['PdDistrictNum'] = LabelEncoder().fit_transform(X.PdDistrict) # H: Different districts have different crimes\n",
    "\n",
    "        # Features from Address\n",
    "        if self.Address_features:\n",
    "            X['Intersection'] = X.Address.apply(lambda x: 1*(\"/\" in x)) # H: Intersections have unique crimes\n",
    "        \n",
    "        # Idea: Make categorical feature of all addresses based on number of crimes at the address\n",
    "        # Idea: Make categorical feature of certain popular streets\n",
    "\n",
    "        # Features from X & Y\n",
    "        # Idea: Make a feature that corresponds to whether the crime was near the ocean. \n",
    "\n",
    "        # Other ideas:\n",
    "        # Certain crimes result in multiple observations (for example the first and second observation in \n",
    "        # the dataset are located) at the same location and occur at the same time. The crimes, warrant arrest \n",
    "        # and traffic violation arrest, seem to go with each other. \n",
    "        #    Specific feature ideas: Number of observations associated with crime. In this case, the value would be 2.\n",
    "        #    Specific feature ideas: If these crimes are split between the training and test datasets, perhaps the crimes\n",
    "        #        in the training data set would inform the crime in the test data set.\n",
    "        return X\n",
    "    \n",
    "\n",
    "class JustNumerics(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.numeric_columns = X.dtypes[X.dtypes != \"object\"].index\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.numeric_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in training data\n",
    "X = pd.read_csv(\"../../data/train.csv\")\n",
    "y = X.pop('Category')\n",
    "\n",
    "# Convert y labels to integer representations\n",
    "labels = LabelEncoder()\n",
    "y = labels.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make train and test data to evaluate base line model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "pipe = Pipeline([(\"feature_engineering\", FeatureEngineering()), (\"just_numerics\", JustNumerics()), (\"RF\", clf)])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict_proba(X_test)\n",
    "\n",
    "# Expected log loss on test data\n",
    "log_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Read in data to predict and make predictions\n",
    "X_predict = pd.read_csv(\"../../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_predictions = pipe.predict_proba(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Export predictions to file to be submitted to Kaggle (Kaggle score = 3.66356)\n",
    "make_Kaggle_file(final_predictions, labels.classes_, decimal_limit=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
